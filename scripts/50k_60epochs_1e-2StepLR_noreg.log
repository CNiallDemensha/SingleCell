Running --> python3 /nas/longleaf/home/athreya/gmm/scripts/train.py --cfg_file=params.json
{'att_dims': 128,
 'batch_size': 2000,
 'clip': 0.01,
 'data_root': '/nas/longleaf/home/athreya/gmm/data/',
 'epochs': 60,
 'exp_dir': '/nas/longleaf/home/athreya/gmm/model/',
 'k': 14,
 'lr': 0.01,
 'resume_from_epoch': -1,
 'seed': 1234,
 'tau': 1,
 'weight_decay': 0}
Device -: cuda:0
Starting training
Iteration 10000 / 40000 - Loss = 44.86906433105469
Iteration 20000 / 40000 - Loss = 44.04934310913086
Iteration 30000 / 40000 - Loss = 43.348323822021484
Average train epoch loss for epoch 1 = 44.350697708129886
Epoch 1 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 1 - Test Loss = 43.009681701660156, Vscore = 0.4349881535364771, ARI = 0.3116381522921912, AMI = 0.4153553007273636
Iteration 10000 / 40000 - Loss = 42.504638671875
Iteration 20000 / 40000 - Loss = 42.011558532714844
Iteration 30000 / 40000 - Loss = 41.373294830322266
Average train epoch loss for epoch 2 = 41.99755992889404
Epoch 2 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 2 - Test Loss = 40.795075225830075, Vscore = 0.48006333623415615, ARI = 0.3326638681240208, AMI = 0.44287692012700364
Iteration 10000 / 40000 - Loss = 40.41426086425781
Iteration 20000 / 40000 - Loss = 39.78916549682617
Iteration 30000 / 40000 - Loss = 39.09000778198242
Average train epoch loss for epoch 3 = 39.82700939178467
Epoch 3 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 3 - Test Loss = 38.75025482177735, Vscore = 0.5748664487844921, ARI = 0.41138237474065176, AMI = 0.5281674353190838
Iteration 10000 / 40000 - Loss = 38.22186279296875
Iteration 20000 / 40000 - Loss = 37.90046310424805
Iteration 30000 / 40000 - Loss = 37.53329849243164
Average train epoch loss for epoch 4 = 37.922193336486814
Epoch 4 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 4 - Test Loss = 37.02315063476563, Vscore = 0.6470402476300428, ARI = 0.5345207043849426, AMI = 0.5986991279381169
Iteration 10000 / 40000 - Loss = 36.47968292236328
Iteration 20000 / 40000 - Loss = 36.395999908447266
Iteration 30000 / 40000 - Loss = 36.3051643371582
Average train epoch loss for epoch 5 = 36.31078033447265
Epoch 5 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 5 - Test Loss = 35.51936340332031, Vscore = 0.7167608357983464, ARI = 0.6745581585937638, AMI = 0.6708918757612254
Iteration 10000 / 40000 - Loss = 35.21708679199219
Iteration 20000 / 40000 - Loss = 34.802284240722656
Iteration 30000 / 40000 - Loss = 34.433868408203125
Average train epoch loss for epoch 6 = 34.877210998535155
Epoch 6 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 6 - Test Loss = 34.17139511108398, Vscore = 0.7613078053278267, ARI = 0.7612701792494966, AMI = 0.7203791750319304
Iteration 10000 / 40000 - Loss = 33.841148376464844
Iteration 20000 / 40000 - Loss = 33.59008026123047
Iteration 30000 / 40000 - Loss = 33.34242248535156
Average train epoch loss for epoch 7 = 33.60064582824707
Epoch 7 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 7 - Test Loss = 32.97284774780273, Vscore = 0.7788001872338846, ARI = 0.7850602831934412, AMI = 0.7412909261336584
Iteration 10000 / 40000 - Loss = 32.6960563659668
Iteration 20000 / 40000 - Loss = 32.49491882324219
Iteration 30000 / 40000 - Loss = 32.15788269042969
Average train epoch loss for epoch 8 = 32.45886936187744
Epoch 8 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 8 - Test Loss = 31.90453758239746, Vscore = 0.7883824470177496, ARI = 0.7947862321470628, AMI = 0.7523782826085212
Iteration 10000 / 40000 - Loss = 31.84071922302246
Iteration 20000 / 40000 - Loss = 31.38956069946289
Iteration 30000 / 40000 - Loss = 31.314138412475586
Average train epoch loss for epoch 9 = 31.449706268310546
Epoch 9 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 9 - Test Loss = 30.966723251342774, Vscore = 0.7937437654960846, ARI = 0.7922671895132379, AMI = 0.7598046866495104
Iteration 10000 / 40000 - Loss = 30.50546646118164
Iteration 20000 / 40000 - Loss = 30.75031852722168
Iteration 30000 / 40000 - Loss = 30.202802658081055
Average train epoch loss for epoch 10 = 30.561028575897218
Epoch 10 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 10 - Test Loss = 30.14662437438965, Vscore = 0.7917410859886996, ARI = 0.785397754603873, AMI = 0.7583988867570526
Iteration 10000 / 40000 - Loss = 30.108652114868164
Iteration 20000 / 40000 - Loss = 29.8096923828125
Iteration 30000 / 40000 - Loss = 29.77089500427246
Average train epoch loss for epoch 11 = 29.80079870223999
Epoch 11 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 11 - Test Loss = 29.46089859008789, Vscore = 0.7877858304004469, ARI = 0.7721505039056555, AMI = 0.7535365073671995
Iteration 10000 / 40000 - Loss = 29.042644500732422
Iteration 20000 / 40000 - Loss = 28.999961853027344
Iteration 30000 / 40000 - Loss = 29.11021614074707
Average train epoch loss for epoch 12 = 29.153833866119385
Epoch 12 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 12 - Test Loss = 28.8852108001709, Vscore = 0.780954755308717, ARI = 0.7574983971196164, AMI = 0.7458740763834928
Iteration 10000 / 40000 - Loss = 28.561216354370117
Iteration 20000 / 40000 - Loss = 28.78067398071289
Iteration 30000 / 40000 - Loss = 28.17906379699707
Average train epoch loss for epoch 13 = 28.618835258483887
Epoch 13 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 13 - Test Loss = 28.382412338256835, Vscore = 0.7721343299764347, ARI = 0.7398439852403373, AMI = 0.7352936584288798
Iteration 10000 / 40000 - Loss = 28.43385887145996
Iteration 20000 / 40000 - Loss = 28.329626083374023
Iteration 30000 / 40000 - Loss = 28.289031982421875
Average train epoch loss for epoch 14 = 28.147172451019287
Epoch 14 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 14 - Test Loss = 27.961596298217774, Vscore = 0.7662015667970505, ARI = 0.7232947914712669, AMI = 0.7276707692115809
Iteration 10000 / 40000 - Loss = 27.879718780517578
Iteration 20000 / 40000 - Loss = 27.84990882873535
Iteration 30000 / 40000 - Loss = 27.77035140991211
Average train epoch loss for epoch 15 = 27.739332008361817
Epoch 15 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 15 - Test Loss = 27.595934677124024, Vscore = 0.7633608803268778, ARI = 0.7103277868053834, AMI = 0.7239030908561995
Iteration 10000 / 40000 - Loss = 27.813255310058594
Iteration 20000 / 40000 - Loss = 27.247220993041992
Iteration 30000 / 40000 - Loss = 27.132320404052734
Average train epoch loss for epoch 16 = 27.410738277435303
Epoch 16 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 16 - Test Loss = 27.28672065734863, Vscore = 0.7586684937844068, ARI = 0.6881804030742864, AMI = 0.7165889336705985
Iteration 10000 / 40000 - Loss = 27.490602493286133
Iteration 20000 / 40000 - Loss = 27.13709831237793
Iteration 30000 / 40000 - Loss = 27.08377456665039
Average train epoch loss for epoch 17 = 27.12165946960449
Epoch 17 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 17 - Test Loss = 27.02704277038574, Vscore = 0.7579419693918329, ARI = 0.6708594675679196, AMI = 0.7143803652829874
Iteration 10000 / 40000 - Loss = 26.774084091186523
Iteration 20000 / 40000 - Loss = 26.493871688842773
Iteration 30000 / 40000 - Loss = 26.993967056274414
Average train epoch loss for epoch 18 = 26.88283567428589
Epoch 18 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 18 - Test Loss = 26.81407928466797, Vscore = 0.751229559152103, ARI = 0.6510169831531697, AMI = 0.7064496660665298
Iteration 10000 / 40000 - Loss = 26.63564109802246
Iteration 20000 / 40000 - Loss = 26.53136444091797
Iteration 30000 / 40000 - Loss = 26.85972023010254
Average train epoch loss for epoch 19 = 26.674719524383544
Epoch 19 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 19 - Test Loss = 26.615196228027344, Vscore = 0.7462296601761989, ARI = 0.6324675914794091, AMI = 0.7006410506864141
Iteration 10000 / 40000 - Loss = 26.57463836669922
Iteration 20000 / 40000 - Loss = 26.546859741210938
Iteration 30000 / 40000 - Loss = 26.111116409301758
Average train epoch loss for epoch 20 = 26.515366649627687
Epoch 20 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 20 - Test Loss = 26.486770248413087, Vscore = 0.7406760180127808, ARI = 0.6173374082638858, AMI = 0.6942876249429516
Iteration 10000 / 40000 - Loss = 26.15888786315918
Iteration 20000 / 40000 - Loss = 26.430185317993164
Iteration 30000 / 40000 - Loss = 26.292383193969727
Average train epoch loss for epoch 21 = 26.354998874664307
Epoch 21 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 21 - Test Loss = 26.365513229370116, Vscore = 0.738569358194913, ARI = 0.610708420347344, AMI = 0.6921115949200107
Iteration 10000 / 40000 - Loss = 26.17298126220703
Iteration 20000 / 40000 - Loss = 26.434770584106445
Iteration 30000 / 40000 - Loss = 26.019569396972656
Average train epoch loss for epoch 22 = 26.278790855407713
Epoch 22 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 22 - Test Loss = 26.31292381286621, Vscore = 0.7359966404958093, ARI = 0.6025544561393616, AMI = 0.6890040617561759
Iteration 10000 / 40000 - Loss = 26.135950088500977
Iteration 20000 / 40000 - Loss = 26.48399543762207
Iteration 30000 / 40000 - Loss = 25.792287826538086
Average train epoch loss for epoch 23 = 26.224240207672118
Epoch 23 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 23 - Test Loss = 26.254368591308594, Vscore = 0.7350624275227222, ARI = 0.5993014742893713, AMI = 0.6879808587169186
Iteration 10000 / 40000 - Loss = 26.21102523803711
Iteration 20000 / 40000 - Loss = 25.9818172454834
Iteration 30000 / 40000 - Loss = 26.026214599609375
Average train epoch loss for epoch 24 = 26.17575674057007
Epoch 24 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 24 - Test Loss = 26.213057708740234, Vscore = 0.7330210478339337, ARI = 0.5943446965468584, AMI = 0.6856194956533601
Iteration 10000 / 40000 - Loss = 26.38331413269043
Iteration 20000 / 40000 - Loss = 25.850318908691406
Iteration 30000 / 40000 - Loss = 26.167274475097656
Average train epoch loss for epoch 25 = 26.13579730987549
Epoch 25 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 25 - Test Loss = 26.173486709594727, Vscore = 0.7305859818005017, ARI = 0.5897210508846052, AMI = 0.6828311497296454
Iteration 10000 / 40000 - Loss = 26.19869613647461
Iteration 20000 / 40000 - Loss = 26.118375778198242
Iteration 30000 / 40000 - Loss = 26.64890480041504
Average train epoch loss for epoch 26 = 26.097303199768067
Epoch 26 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 26 - Test Loss = 26.137701416015624, Vscore = 0.7293739337155649, ARI = 0.5853357576816706, AMI = 0.6812592360259458
Iteration 10000 / 40000 - Loss = 25.819520950317383
Iteration 20000 / 40000 - Loss = 26.122121810913086
Iteration 30000 / 40000 - Loss = 26.142059326171875
Average train epoch loss for epoch 27 = 26.061934089660646
Epoch 27 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 27 - Test Loss = 26.113521575927734, Vscore = 0.7274925507292691, ARI = 0.5808384319361705, AMI = 0.678859112382106
Iteration 10000 / 40000 - Loss = 25.84967803955078
Iteration 20000 / 40000 - Loss = 26.178985595703125
Iteration 30000 / 40000 - Loss = 25.910154342651367
Average train epoch loss for epoch 28 = 26.03440237045288
Epoch 28 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 28 - Test Loss = 26.071007919311523, Vscore = 0.7265339525442622, ARI = 0.5805627181982735, AMI = 0.6778282612274954
Iteration 10000 / 40000 - Loss = 25.74809455871582
Iteration 20000 / 40000 - Loss = 25.968704223632812
Iteration 30000 / 40000 - Loss = 26.178813934326172
Average train epoch loss for epoch 29 = 26.01155843734741
Epoch 29 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 29 - Test Loss = 26.0553840637207, Vscore = 0.7259405475251709, ARI = 0.576181150546515, AMI = 0.6771775410133504
Iteration 10000 / 40000 - Loss = 26.19954490661621
Iteration 20000 / 40000 - Loss = 26.06442642211914
Iteration 30000 / 40000 - Loss = 26.01390266418457
Average train epoch loss for epoch 30 = 25.98342294692993
Epoch 30 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 30 - Test Loss = 26.02559623718262, Vscore = 0.7236404500789161, ARI = 0.5729192579849869, AMI = 0.6745813235238032
Iteration 10000 / 40000 - Loss = 25.889001846313477
Iteration 20000 / 40000 - Loss = 25.602832794189453
Iteration 30000 / 40000 - Loss = 26.203182220458984
Average train epoch loss for epoch 31 = 25.95983142852783
Epoch 31 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 31 - Test Loss = 25.996537017822266, Vscore = 0.7227326112307692, ARI = 0.5706212003341414, AMI = 0.6733711143621246
Iteration 10000 / 40000 - Loss = 26.01479148864746
Iteration 20000 / 40000 - Loss = 25.94300079345703
Iteration 30000 / 40000 - Loss = 25.867704391479492
Average train epoch loss for epoch 32 = 25.93357753753662
Epoch 32 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 32 - Test Loss = 25.970194625854493, Vscore = 0.7215242861856266, ARI = 0.5658972036956874, AMI = 0.6718210360773239
Iteration 10000 / 40000 - Loss = 25.791778564453125
Iteration 20000 / 40000 - Loss = 25.912914276123047
Iteration 30000 / 40000 - Loss = 26.07223892211914
Average train epoch loss for epoch 33 = 25.91558666229248
Epoch 33 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 33 - Test Loss = 25.958930206298827, Vscore = 0.7199969511665477, ARI = 0.5631309743115583, AMI = 0.6700737962496152
Iteration 10000 / 40000 - Loss = 25.87811279296875
Iteration 20000 / 40000 - Loss = 25.992158889770508
Iteration 30000 / 40000 - Loss = 25.707321166992188
Average train epoch loss for epoch 34 = 25.89763126373291
Epoch 34 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 34 - Test Loss = 25.923311614990233, Vscore = 0.7178363422122103, ARI = 0.5594197231948798, AMI = 0.6674983372657219
Iteration 10000 / 40000 - Loss = 26.10466194152832
Iteration 20000 / 40000 - Loss = 25.97112274169922
Iteration 30000 / 40000 - Loss = 25.439176559448242
Average train epoch loss for epoch 35 = 25.868631839752197
Epoch 35 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 35 - Test Loss = 25.904101181030274, Vscore = 0.7165061127486341, ARI = 0.556048165324517, AMI = 0.6656820396273088
Iteration 10000 / 40000 - Loss = 25.77366828918457
Iteration 20000 / 40000 - Loss = 25.908180236816406
Iteration 30000 / 40000 - Loss = 25.911483764648438
Average train epoch loss for epoch 36 = 25.84965648651123
Epoch 36 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 36 - Test Loss = 25.868529510498046, Vscore = 0.7143635804990798, ARI = 0.5525468235522137, AMI = 0.6625565288272338
Iteration 10000 / 40000 - Loss = 25.832056045532227
Iteration 20000 / 40000 - Loss = 25.787567138671875
Iteration 30000 / 40000 - Loss = 25.592042922973633
Average train epoch loss for epoch 37 = 25.82226142883301
Epoch 37 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 37 - Test Loss = 25.846459579467773, Vscore = 0.7130678398817131, ARI = 0.549029461972376, AMI = 0.6607889580679308
Iteration 10000 / 40000 - Loss = 25.650930404663086
Iteration 20000 / 40000 - Loss = 25.754989624023438
Iteration 30000 / 40000 - Loss = 26.061429977416992
Average train epoch loss for epoch 38 = 25.798779010772705
Epoch 38 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 38 - Test Loss = 25.82322883605957, Vscore = 0.7126385152925141, ARI = 0.5466537819943323, AMI = 0.6595422319660545
Iteration 10000 / 40000 - Loss = 25.768293380737305
Iteration 20000 / 40000 - Loss = 25.947702407836914
Iteration 30000 / 40000 - Loss = 25.83789825439453
Average train epoch loss for epoch 39 = 25.772319889068605
Epoch 39 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 39 - Test Loss = 25.79691925048828, Vscore = 0.7122518709524467, ARI = 0.5470733005201426, AMI = 0.6586262581036558
Iteration 10000 / 40000 - Loss = 25.62738800048828
Iteration 20000 / 40000 - Loss = 25.741455078125
Iteration 30000 / 40000 - Loss = 25.615703582763672
Average train epoch loss for epoch 40 = 25.747905921936034
Epoch 40 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 40 - Test Loss = 25.767540740966798, Vscore = 0.7090433945073863, ARI = 0.5387803787808955, AMI = 0.6549638035119435
Iteration 10000 / 40000 - Loss = 25.49402618408203
Iteration 20000 / 40000 - Loss = 25.472440719604492
Iteration 30000 / 40000 - Loss = 25.637168884277344
Average train epoch loss for epoch 41 = 25.69152202606201
Epoch 41 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 41 - Test Loss = 25.725695037841795, Vscore = 0.7092398585948907, ARI = 0.5396743120495455, AMI = 0.6547655785658598
Iteration 10000 / 40000 - Loss = 25.840883255004883
Iteration 20000 / 40000 - Loss = 25.58425521850586
Iteration 30000 / 40000 - Loss = 25.62308692932129
Average train epoch loss for epoch 42 = 25.66577854156494
Epoch 42 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 42 - Test Loss = 25.712833404541016, Vscore = 0.7082941224888856, ARI = 0.5374173679736607, AMI = 0.653612147075459
Iteration 10000 / 40000 - Loss = 25.856908798217773
Iteration 20000 / 40000 - Loss = 25.384239196777344
Iteration 30000 / 40000 - Loss = 25.533489227294922
Average train epoch loss for epoch 43 = 25.65540952682495
Epoch 43 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 43 - Test Loss = 25.70292434692383, Vscore = 0.7083822965818494, ARI = 0.5375010928117007, AMI = 0.6534802873637323
Iteration 10000 / 40000 - Loss = 26.01584815979004
Iteration 20000 / 40000 - Loss = 25.530025482177734
Iteration 30000 / 40000 - Loss = 25.72390365600586
Average train epoch loss for epoch 44 = 25.64189033508301
Epoch 44 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 44 - Test Loss = 25.692385864257812, Vscore = 0.707142581406361, ARI = 0.5353639964952721, AMI = 0.6518392545303738
Iteration 10000 / 40000 - Loss = 25.812204360961914
Iteration 20000 / 40000 - Loss = 25.693639755249023
Iteration 30000 / 40000 - Loss = 25.621273040771484
Average train epoch loss for epoch 45 = 25.632863521575928
Epoch 45 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 45 - Test Loss = 25.682719039916993, Vscore = 0.7062841928869477, ARI = 0.5331493126008904, AMI = 0.6508505360795379
Iteration 10000 / 40000 - Loss = 25.868730545043945
Iteration 20000 / 40000 - Loss = 25.814537048339844
Iteration 30000 / 40000 - Loss = 25.54486083984375
Average train epoch loss for epoch 46 = 25.62154197692871
Epoch 46 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 46 - Test Loss = 25.66883239746094, Vscore = 0.7063162377437785, ARI = 0.5329184992216504, AMI = 0.650650278819735
Iteration 10000 / 40000 - Loss = 25.949743270874023
Iteration 20000 / 40000 - Loss = 25.36688804626465
Iteration 30000 / 40000 - Loss = 25.581958770751953
Average train epoch loss for epoch 47 = 25.61307210922241
Epoch 47 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 47 - Test Loss = 25.665922927856446, Vscore = 0.7047349474002527, ARI = 0.5298992661003397, AMI = 0.6487610304738359
Iteration 10000 / 40000 - Loss = 25.901845932006836
Iteration 20000 / 40000 - Loss = 25.013471603393555
Iteration 30000 / 40000 - Loss = 26.014057159423828
Average train epoch loss for epoch 48 = 25.604233741760254
Epoch 48 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 48 - Test Loss = 25.65482978820801, Vscore = 0.7050045258343434, ARI = 0.5305319615641103, AMI = 0.6489139918560645
Iteration 10000 / 40000 - Loss = 25.403963088989258
Iteration 20000 / 40000 - Loss = 25.3803653717041
Iteration 30000 / 40000 - Loss = 25.787778854370117
Average train epoch loss for epoch 49 = 25.59493417739868
Epoch 49 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 49 - Test Loss = 25.64632568359375, Vscore = 0.7042659426632603, ARI = 0.5289465502312332, AMI = 0.6480335944628496
Iteration 10000 / 40000 - Loss = 25.750181198120117
Iteration 20000 / 40000 - Loss = 25.574783325195312
Iteration 30000 / 40000 - Loss = 25.261247634887695
Average train epoch loss for epoch 50 = 25.584485912322997
Epoch 50 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 50 - Test Loss = 25.635317230224608, Vscore = 0.704251770949435, ARI = 0.5276018339881304, AMI = 0.6478834712888732
Iteration 10000 / 40000 - Loss = 25.378625869750977
Iteration 20000 / 40000 - Loss = 25.46384048461914
Iteration 30000 / 40000 - Loss = 25.984853744506836
Average train epoch loss for epoch 51 = 25.576740169525145
Epoch 51 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 51 - Test Loss = 25.632601928710937, Vscore = 0.7026591451074171, ARI = 0.5243976809585864, AMI = 0.6458998736336277
Iteration 10000 / 40000 - Loss = 25.283462524414062
Iteration 20000 / 40000 - Loss = 25.09075164794922
Iteration 30000 / 40000 - Loss = 25.65577507019043
Average train epoch loss for epoch 52 = 25.565984630584715
Epoch 52 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 52 - Test Loss = 25.61830711364746, Vscore = 0.7028133037308232, ARI = 0.5241430965743317, AMI = 0.6460034881570422
Iteration 10000 / 40000 - Loss = 25.705116271972656
Iteration 20000 / 40000 - Loss = 25.493637084960938
Iteration 30000 / 40000 - Loss = 25.24578094482422
Average train epoch loss for epoch 53 = 25.557670402526856
Epoch 53 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 53 - Test Loss = 25.612158584594727, Vscore = 0.7022174122586703, ARI = 0.5218149676296959, AMI = 0.6453208270524862
Iteration 10000 / 40000 - Loss = 25.479063034057617
Iteration 20000 / 40000 - Loss = 25.372228622436523
Iteration 30000 / 40000 - Loss = 25.54361343383789
Average train epoch loss for epoch 54 = 25.547853565216066
Epoch 54 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 54 - Test Loss = 25.60246124267578, Vscore = 0.7022803177955613, ARI = 0.5214838911723447, AMI = 0.6450221672386497
Iteration 10000 / 40000 - Loss = 25.631376266479492
Iteration 20000 / 40000 - Loss = 25.591337203979492
Iteration 30000 / 40000 - Loss = 25.854021072387695
Average train epoch loss for epoch 55 = 25.5421124458313
Epoch 55 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 55 - Test Loss = 25.604594802856447, Vscore = 0.7027214789478838, ARI = 0.5217299724997232, AMI = 0.6452176700671091
Test loss 25.604594802856447 not better than previous best test loss 25.60246124267578. Skipping saving model
Iteration 10000 / 40000 - Loss = 25.271821975708008
Iteration 20000 / 40000 - Loss = 25.288137435913086
Iteration 30000 / 40000 - Loss = 25.52877426147461
Average train epoch loss for epoch 56 = 25.53461046218872
Epoch 56 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 56 - Test Loss = 25.59921875, Vscore = 0.7016977002294211, ARI = 0.5188999174759288, AMI = 0.644150065374217
Iteration 10000 / 40000 - Loss = 25.383817672729492
Iteration 20000 / 40000 - Loss = 25.357128143310547
Iteration 30000 / 40000 - Loss = 25.44000244140625
Average train epoch loss for epoch 57 = 25.527302837371828
Epoch 57 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 57 - Test Loss = 25.584469985961913, Vscore = 0.7016134112176076, ARI = 0.5184789942744833, AMI = 0.6438329633558075
Iteration 10000 / 40000 - Loss = 25.726016998291016
Iteration 20000 / 40000 - Loss = 25.572837829589844
Iteration 30000 / 40000 - Loss = 25.193361282348633
Average train epoch loss for epoch 58 = 25.51580390930176
Epoch 58 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 58 - Test Loss = 25.575485229492188, Vscore = 0.7011206021259625, ARI = 0.5172888200920468, AMI = 0.6430113455519362
Iteration 10000 / 40000 - Loss = 25.42247772216797
Iteration 20000 / 40000 - Loss = 25.36216163635254
Iteration 30000 / 40000 - Loss = 25.583162307739258
Average train epoch loss for epoch 59 = 25.505628681182863
Epoch 59 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 59 - Test Loss = 25.574362182617186, Vscore = 0.7013048824121989, ARI = 0.5168815802731002, AMI = 0.6429926316392383
Iteration 10000 / 40000 - Loss = 25.363563537597656
Iteration 20000 / 40000 - Loss = 25.634479522705078
Iteration 30000 / 40000 - Loss = 25.4604549407959
Average train epoch loss for epoch 60 = 25.49750909805298
Epoch 60 - Eval mode
Test label shape = (10000,), Predicted label shape = (10000,)
Epoch 60 - Test Loss = 25.55452194213867, Vscore = 0.7008587041843839, ARI = 0.5149885998440634, AMI = 0.6423554066310646
Training finished
Epoch level Train_Loss, Test_Loss, V_Score, ARI, AMI -:
[44.350697708129886, 41.99755992889404, 39.82700939178467, 37.922193336486814, 36.31078033447265, 34.877210998535155, 33.60064582824707, 32.45886936187744, 31.449706268310546, 30.561028575897218, 29.80079870223999, 29.153833866119385, 28.618835258483887, 28.147172451019287, 27.739332008361817, 27.410738277435303, 27.12165946960449, 26.88283567428589, 26.674719524383544, 26.515366649627687, 26.354998874664307, 26.278790855407713, 26.224240207672118, 26.17575674057007, 26.13579730987549, 26.097303199768067, 26.061934089660646, 26.03440237045288, 26.01155843734741, 25.98342294692993, 25.95983142852783, 25.93357753753662, 25.91558666229248, 25.89763126373291, 25.868631839752197, 25.84965648651123, 25.82226142883301, 25.798779010772705, 25.772319889068605, 25.747905921936034, 25.69152202606201, 25.66577854156494, 25.65540952682495, 25.64189033508301, 25.632863521575928, 25.62154197692871, 25.61307210922241, 25.604233741760254, 25.59493417739868, 25.584485912322997, 25.576740169525145, 25.565984630584715, 25.557670402526856, 25.547853565216066, 25.5421124458313, 25.53461046218872, 25.527302837371828, 25.51580390930176, 25.505628681182863, 25.49750909805298]
[43.009681701660156, 40.795075225830075, 38.75025482177735, 37.02315063476563, 35.51936340332031, 34.17139511108398, 32.97284774780273, 31.90453758239746, 30.966723251342774, 30.14662437438965, 29.46089859008789, 28.8852108001709, 28.382412338256835, 27.961596298217774, 27.595934677124024, 27.28672065734863, 27.02704277038574, 26.81407928466797, 26.615196228027344, 26.486770248413087, 26.365513229370116, 26.31292381286621, 26.254368591308594, 26.213057708740234, 26.173486709594727, 26.137701416015624, 26.113521575927734, 26.071007919311523, 26.0553840637207, 26.02559623718262, 25.996537017822266, 25.970194625854493, 25.958930206298827, 25.923311614990233, 25.904101181030274, 25.868529510498046, 25.846459579467773, 25.82322883605957, 25.79691925048828, 25.767540740966798, 25.725695037841795, 25.712833404541016, 25.70292434692383, 25.692385864257812, 25.682719039916993, 25.66883239746094, 25.665922927856446, 25.65482978820801, 25.64632568359375, 25.635317230224608, 25.632601928710937, 25.61830711364746, 25.612158584594727, 25.60246124267578, 25.604594802856447, 25.59921875, 25.584469985961913, 25.575485229492188, 25.574362182617186, 25.55452194213867]
[0.4349881535364771, 0.48006333623415615, 0.5748664487844921, 0.6470402476300428, 0.7167608357983464, 0.7613078053278267, 0.7788001872338846, 0.7883824470177496, 0.7937437654960846, 0.7917410859886996, 0.7877858304004469, 0.780954755308717, 0.7721343299764347, 0.7662015667970505, 0.7633608803268778, 0.7586684937844068, 0.7579419693918329, 0.751229559152103, 0.7462296601761989, 0.7406760180127808, 0.738569358194913, 0.7359966404958093, 0.7350624275227222, 0.7330210478339337, 0.7305859818005017, 0.7293739337155649, 0.7274925507292691, 0.7265339525442622, 0.7259405475251709, 0.7236404500789161, 0.7227326112307692, 0.7215242861856266, 0.7199969511665477, 0.7178363422122103, 0.7165061127486341, 0.7143635804990798, 0.7130678398817131, 0.7126385152925141, 0.7122518709524467, 0.7090433945073863, 0.7092398585948907, 0.7082941224888856, 0.7083822965818494, 0.707142581406361, 0.7062841928869477, 0.7063162377437785, 0.7047349474002527, 0.7050045258343434, 0.7042659426632603, 0.704251770949435, 0.7026591451074171, 0.7028133037308232, 0.7022174122586703, 0.7022803177955613, 0.7027214789478838, 0.7016977002294211, 0.7016134112176076, 0.7011206021259625, 0.7013048824121989, 0.7008587041843839]
[0.3116381522921912, 0.3326638681240208, 0.41138237474065176, 0.5345207043849426, 0.6745581585937638, 0.7612701792494966, 0.7850602831934412, 0.7947862321470628, 0.7922671895132379, 0.785397754603873, 0.7721505039056555, 0.7574983971196164, 0.7398439852403373, 0.7232947914712669, 0.7103277868053834, 0.6881804030742864, 0.6708594675679196, 0.6510169831531697, 0.6324675914794091, 0.6173374082638858, 0.610708420347344, 0.6025544561393616, 0.5993014742893713, 0.5943446965468584, 0.5897210508846052, 0.5853357576816706, 0.5808384319361705, 0.5805627181982735, 0.576181150546515, 0.5729192579849869, 0.5706212003341414, 0.5658972036956874, 0.5631309743115583, 0.5594197231948798, 0.556048165324517, 0.5525468235522137, 0.549029461972376, 0.5466537819943323, 0.5470733005201426, 0.5387803787808955, 0.5396743120495455, 0.5374173679736607, 0.5375010928117007, 0.5353639964952721, 0.5331493126008904, 0.5329184992216504, 0.5298992661003397, 0.5305319615641103, 0.5289465502312332, 0.5276018339881304, 0.5243976809585864, 0.5241430965743317, 0.5218149676296959, 0.5214838911723447, 0.5217299724997232, 0.5188999174759288, 0.5184789942744833, 0.5172888200920468, 0.5168815802731002, 0.5149885998440634]
[0.4153553007273636, 0.44287692012700364, 0.5281674353190838, 0.5986991279381169, 0.6708918757612254, 0.7203791750319304, 0.7412909261336584, 0.7523782826085212, 0.7598046866495104, 0.7583988867570526, 0.7535365073671995, 0.7458740763834928, 0.7352936584288798, 0.7276707692115809, 0.7239030908561995, 0.7165889336705985, 0.7143803652829874, 0.7064496660665298, 0.7006410506864141, 0.6942876249429516, 0.6921115949200107, 0.6890040617561759, 0.6879808587169186, 0.6856194956533601, 0.6828311497296454, 0.6812592360259458, 0.678859112382106, 0.6778282612274954, 0.6771775410133504, 0.6745813235238032, 0.6733711143621246, 0.6718210360773239, 0.6700737962496152, 0.6674983372657219, 0.6656820396273088, 0.6625565288272338, 0.6607889580679308, 0.6595422319660545, 0.6586262581036558, 0.6549638035119435, 0.6547655785658598, 0.653612147075459, 0.6534802873637323, 0.6518392545303738, 0.6508505360795379, 0.650650278819735, 0.6487610304738359, 0.6489139918560645, 0.6480335944628496, 0.6478834712888732, 0.6458998736336277, 0.6460034881570422, 0.6453208270524862, 0.6450221672386497, 0.6452176700671091, 0.644150065374217, 0.6438329633558075, 0.6430113455519362, 0.6429926316392383, 0.6423554066310646]
Performing k-means clustering to 14 components of 40000 samples in dimension 32/32 ...
K-means took: 4.132985353469849 sec
KMeans V_Score, ARI, AMI -: 0.23192511763990464, 0.10239438383572112, 0.22538507586467463
